{"version":3,"sources":["../../src/utils/stream.ts","../../src/utils/openai.ts"],"sourcesContent":["import {\n  Action,\n  parseChatCompletion,\n  ToolCallPayload,\n  ChatCompletionChunk,\n} from \"@copilotkit/shared\";\nimport {\n  writeChatCompletionChunk,\n  writeChatCompletionContent,\n  writeChatCompletionEnd,\n  writeChatCompletionResult,\n} from \"./openai\";\n\n/**\n * Execute a function call and write the result to the stream.\n * TODO: should this return a stream to get process other function calls?\n */\nasync function executeFunctionCall(\n  controller: ReadableStreamDefaultController<any>,\n  action: Action<any>,\n  functionCallArguments: string,\n): Promise<void> {\n  // Prepare arguments for function calling\n  let args: Record<string, any>[] = [];\n  if (functionCallArguments) {\n    args = JSON.parse(functionCallArguments);\n  }\n\n  // call the function\n  const result = await action.handler(args);\n\n  // We support several types of return values from functions:\n\n  // 1. string\n  // Just send the result as the content of the chunk.\n  if (result && typeof result === \"string\") {\n    writeChatCompletionResult(controller, action.name, result);\n  }\n\n  // 2. AIMessage\n  // Send the content and function call of the AIMessage as the content of the chunk.\n  else if (result && \"content\" in result && typeof result.content === \"string\") {\n    writeChatCompletionContent(controller, result.content, result.additional_kwargs?.tool_calls);\n  }\n\n  // 3. BaseMessageChunk\n  // Send the content and function call of the AIMessage as the content of the chunk.\n  else if (result && \"lc_kwargs\" in result) {\n    writeChatCompletionContent(controller, result.lc_kwargs?.content, result.lc_kwargs?.tool_calls);\n  }\n\n  // 4. IterableReadableStream\n  // Stream the result of the LangChain function.\n  else if (result && \"getReader\" in result) {\n    let reader = result.getReader();\n    while (true) {\n      try {\n        const { done, value } = await reader.read();\n\n        if (done) {\n          break;\n        }\n\n        writeChatCompletionContent(\n          controller,\n          value?.lc_kwargs?.content,\n          value.lc_kwargs?.additional_kwargs?.tool_calls,\n        );\n      } catch (error) {\n        console.error(\"Error reading from stream\", error);\n        break;\n      }\n    }\n  }\n\n  // 5. Any other type, return JSON result\n  else {\n    writeChatCompletionResult(controller, action.name, result);\n  }\n}\n\n/**\n * This function intercepts the stream from the chat completion and processes it according to the defined actions.\n * It decodes the stream, executes any server-side functions as specified in the actions, and forwards the rest to the client.\n *\n * @param stream - The incoming ReadableStream of Uint8Array from the chat completion.\n * @param actions - An array of Action objects that define server-side functions to be executed.\n * @param debug - A boolean flag to enable debug logging.\n * @returns A new ReadableStream that is the result of processing the incoming stream.\n */\nexport function copilotkitStreamInterceptor(\n  stream: ReadableStream<Uint8Array>,\n  actions: Action<any>[],\n  debug: boolean = false,\n): ReadableStream {\n  const functionsByName = actions.reduce(\n    (acc, fn) => {\n      acc[fn.name] = fn;\n      return acc;\n    },\n    {} as Record<string, Action<any>>,\n  );\n\n  const decodedStream = parseChatCompletion(stream);\n  const reader = decodedStream.getReader();\n\n  async function cleanup(controller?: ReadableStreamDefaultController<any>) {\n    if (controller) {\n      try {\n        controller.close();\n      } catch (_) {}\n    }\n    if (reader) {\n      try {\n        await reader.cancel();\n      } catch (_) {}\n    }\n  }\n\n  // Keep track of current state as we process the stream\n\n  // Loop Invariant:\n  // Either we are in the middle of a function call that should be executed on the backend = TRUE\n  // or we are in the middle of processing a chunk that should be forwarded to the client = FALSE\n  let executeThisFunctionCall = false;\n\n  let functionCallName = \"\";\n  let functionCallArguments = \"\";\n\n  let currentFnIndex: number | null = null;\n\n  const flushFunctionCall = async (\n    controller: ReadableStreamDefaultController<any>,\n  ): Promise<void> => {\n    const action = functionsByName[functionCallName];\n    await executeFunctionCall(controller, action, functionCallArguments);\n\n    executeThisFunctionCall = false;\n    functionCallName = \"\";\n    functionCallArguments = \"\";\n  };\n\n  return new ReadableStream({\n    async pull(controller) {\n      while (true) {\n        try {\n          const { done, value } = await reader.read();\n\n          if (done) {\n            if (debug) {\n              console.log(\"data: [DONE]\\n\\n\");\n            }\n            if (executeThisFunctionCall) {\n              // We are at the end of the stream and still have a function call to execute\n              await flushFunctionCall(controller);\n            }\n            writeChatCompletionEnd(controller);\n            await cleanup(controller);\n            return;\n          } // done == true (terminal case)\n\n          if (debug) {\n            console.log(\"data: \" + JSON.stringify(value) + \"\\n\\n\");\n          }\n\n          type Mode = { type: \"function\"; toolCall: ToolCallPayload } | { type: \"message\" };\n\n          let mode: Mode;\n          const maybeToolCall = value.choices[0].delta.tool_calls?.[0];\n          if (maybeToolCall) {\n            mode = { type: \"function\", toolCall: maybeToolCall };\n          } else {\n            mode = { type: \"message\" };\n          }\n\n          const nextChunkIndex = mode.type === \"function\" ? mode.toolCall.index : null;\n          // If We are in the middle of a function call and got a non function call chunk\n          // or a different function call\n          // => execute the function call first\n          if (\n            executeThisFunctionCall &&\n            (mode.type != \"function\" || nextChunkIndex != currentFnIndex)\n          ) {\n            await flushFunctionCall(controller);\n          }\n          currentFnIndex = nextChunkIndex;\n\n          // if we get a message, emit the content and continue;\n          if (mode.type === \"message\") {\n            if (value.choices[0].delta.content) {\n              writeChatCompletionChunk(controller, value);\n            }\n            continue;\n          }\n\n          // if we get a function call, emit it only if we don't execute it server side\n          else if (mode.type === \"function\") {\n            // Set the function name if present\n            const maybeFunctionName = mode.toolCall.function.name;\n            if (maybeFunctionName) {\n              functionCallName = maybeFunctionName;\n            }\n            // If we have argument streamed back, add them to the function call arguments\n            const maybeArguments = mode.toolCall.function.arguments;\n            if (mode.toolCall.function.arguments) {\n              functionCallArguments += maybeArguments;\n            }\n            if (!executeThisFunctionCall) {\n              // Decide if we should execute the function call server side\n              if (functionCallName in functionsByName) {\n                executeThisFunctionCall = true;\n              }\n            }\n            mode.toolCall.function.scope = executeThisFunctionCall ? \"server\" : \"client\";\n            writeChatCompletionChunk(controller, value);\n            continue;\n          }\n        } catch (error) {\n          controller.error(error);\n          return;\n        }\n      }\n    },\n    cancel() {\n      reader.cancel();\n    },\n  });\n}\n\n/**\n * A ReadableStream that only emits a single chunk.\n */\nexport class SingleChunkReadableStream extends ReadableStream<any> {\n  constructor(content: string = \"\", toolCalls?: any) {\n    super({\n      start(controller) {\n        const chunk: ChatCompletionChunk = {\n          choices: [\n            {\n              delta: {\n                role: \"assistant\",\n                content,\n                ...(toolCalls ? { tool_calls: toolCalls } : {}),\n              },\n            },\n          ],\n        };\n        writeChatCompletionChunk(controller, chunk);\n        writeChatCompletionEnd(controller);\n\n        controller.close();\n      },\n      cancel() {},\n    });\n  }\n}\n","import { Message, ToolDefinition, ChatCompletionChunk, encodeResult } from \"@copilotkit/shared\";\n\nexport function writeChatCompletionChunk(\n  controller: ReadableStreamDefaultController<any>,\n  chunk: ChatCompletionChunk,\n) {\n  const payload = new TextEncoder().encode(\"data: \" + JSON.stringify(chunk) + \"\\n\\n\");\n  controller!.enqueue(payload);\n}\n\nexport function writeChatCompletionContent(\n  controller: ReadableStreamDefaultController<any>,\n  content: string = \"\",\n  toolCalls?: any,\n) {\n  const chunk: ChatCompletionChunk = {\n    choices: [\n      {\n        delta: {\n          role: \"assistant\",\n          content: content,\n          ...(toolCalls ? { tool_calls: toolCalls } : {}),\n        },\n      },\n    ],\n  };\n\n  writeChatCompletionChunk(controller, chunk);\n}\n\nexport function writeChatCompletionResult(\n  controller: ReadableStreamDefaultController<any>,\n  functionName: string,\n  result: any,\n) {\n  let resultString = encodeResult(result);\n\n  const chunk: ChatCompletionChunk = {\n    choices: [\n      {\n        delta: {\n          role: \"function\",\n          content: resultString,\n          name: functionName,\n        },\n      },\n    ],\n  };\n\n  writeChatCompletionChunk(controller, chunk);\n}\n\nexport function writeChatCompletionEnd(controller: ReadableStreamDefaultController<any>) {\n  const payload = new TextEncoder().encode(\"data: [DONE]\\n\\n\");\n  controller.enqueue(payload);\n}\n\nexport function limitOpenAIMessagesToTokenCount(\n  messages: Message[],\n  tools: ToolDefinition[],\n  maxTokens: number,\n): Message[] {\n  const result: Message[] = [];\n  const toolsNumTokens = countToolsTokens(tools);\n  if (toolsNumTokens > maxTokens) {\n    throw new Error(`Too many tokens in function definitions: ${toolsNumTokens} > ${maxTokens}`);\n  }\n  maxTokens -= toolsNumTokens;\n\n  for (const message of messages) {\n    if (message.role === \"system\") {\n      const numTokens = countMessageTokens(message);\n      maxTokens -= numTokens;\n\n      if (maxTokens < 0) {\n        throw new Error(\"Not enough tokens for system message.\");\n      }\n    }\n  }\n\n  let cutoff: boolean = false;\n\n  const reversedMessages = [...messages].reverse();\n  for (const message of reversedMessages) {\n    if (message.role === \"system\") {\n      result.unshift(message);\n      continue;\n    } else if (cutoff) {\n      continue;\n    }\n    let numTokens = countMessageTokens(message);\n    if (maxTokens < numTokens) {\n      cutoff = true;\n      continue;\n    }\n    result.unshift(message);\n    maxTokens -= numTokens;\n  }\n\n  return result;\n}\n\nexport function maxTokensForOpenAIModel(model: string): number {\n  return maxTokensByModel[model] || DEFAULT_MAX_TOKENS;\n}\n\nconst DEFAULT_MAX_TOKENS = 8192;\n\nconst maxTokensByModel: { [key: string]: number } = {\n  // GPT-4\n  \"gpt-4-0125-preview\": 128000,\n  \"gpt-4-turbo-preview\": 128000,\n  \"gpt-4-1106-preview\": 128000,\n  \"gpt-4-vision-preview\": 128000,\n  \"gpt-4-1106-vision-preview\": 128000,\n  \"gpt-4-32k\": 32768,\n  \"gpt-4-32k-0613\": 32768,\n  \"gpt-4-32k-0314\": 32768,\n  \"gpt-4\": 8192,\n  \"gpt-4-0613\": 8192,\n  \"gpt-4-0314\": 8192,\n\n  // GPT-3.5\n  \"gpt-3.5-turbo-0125\": 16385,\n  \"gpt-3.5-turbo\": 16385,\n  \"gpt-3.5-turbo-1106\": 16385,\n  \"gpt-3.5-turbo-instruct\": 4096,\n  \"gpt-3.5-turbo-16k\": 16385,\n  \"gpt-3.5-turbo-0613\": 4096,\n  \"gpt-3.5-turbo-16k-0613\": 16385,\n  \"gpt-3.5-turbo-0301\": 4097,\n};\n\nfunction countToolsTokens(functions: ToolDefinition[]): number {\n  if (functions.length === 0) {\n    return 0;\n  }\n  const json = JSON.stringify(functions);\n  return countTokens(json);\n}\n\nfunction countMessageTokens(message: Message): number {\n  if (message.content) {\n    return countTokens(message.content);\n  } else if (message.function_call) {\n    return countTokens(JSON.stringify(message.function_call));\n  }\n  return 0;\n}\n\nfunction countTokens(text: string): number {\n  return text.length / 3;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAAAA,iBAKO;;;ACLP,oBAA2E;AAEpE,SAAS,yBACd,YACA,OACA;AACA,QAAM,UAAU,IAAI,YAAY,EAAE,OAAO,WAAW,KAAK,UAAU,KAAK,IAAI,MAAM;AAClF,aAAY,QAAQ,OAAO;AAC7B;AAEO,SAAS,2BACd,YACA,UAAkB,IAClB,WACA;AACA,QAAM,QAA6B;AAAA,IACjC,SAAS;AAAA,MACP;AAAA,QACE,OAAO;AAAA,UACL,MAAM;AAAA,UACN;AAAA,UACA,GAAI,YAAY,EAAE,YAAY,UAAU,IAAI,CAAC;AAAA,QAC/C;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,2BAAyB,YAAY,KAAK;AAC5C;AAEO,SAAS,0BACd,YACA,cACA,QACA;AACA,MAAI,mBAAe,4BAAa,MAAM;AAEtC,QAAM,QAA6B;AAAA,IACjC,SAAS;AAAA,MACP;AAAA,QACE,OAAO;AAAA,UACL,MAAM;AAAA,UACN,SAAS;AAAA,UACT,MAAM;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,2BAAyB,YAAY,KAAK;AAC5C;AAEO,SAAS,uBAAuB,YAAkD;AACvF,QAAM,UAAU,IAAI,YAAY,EAAE,OAAO,kBAAkB;AAC3D,aAAW,QAAQ,OAAO;AAC5B;;;ADtCA,eAAe,oBACb,YACA,QACA,uBACe;AArBjB;AAuBE,MAAI,OAA8B,CAAC;AACnC,MAAI,uBAAuB;AACzB,WAAO,KAAK,MAAM,qBAAqB;AAAA,EACzC;AAGA,QAAM,SAAS,MAAM,OAAO,QAAQ,IAAI;AAMxC,MAAI,UAAU,OAAO,WAAW,UAAU;AACxC,8BAA0B,YAAY,OAAO,MAAM,MAAM;AAAA,EAC3D,WAIS,UAAU,aAAa,UAAU,OAAO,OAAO,YAAY,UAAU;AAC5E,+BAA2B,YAAY,OAAO,UAAS,YAAO,sBAAP,mBAA0B,UAAU;AAAA,EAC7F,WAIS,UAAU,eAAe,QAAQ;AACxC,+BAA2B,aAAY,YAAO,cAAP,mBAAkB,UAAS,YAAO,cAAP,mBAAkB,UAAU;AAAA,EAChG,WAIS,UAAU,eAAe,QAAQ;AACxC,QAAI,SAAS,OAAO,UAAU;AAC9B,WAAO,MAAM;AACX,UAAI;AACF,cAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAE1C,YAAI,MAAM;AACR;AAAA,QACF;AAEA;AAAA,UACE;AAAA,WACA,oCAAO,cAAP,mBAAkB;AAAA,WAClB,iBAAM,cAAN,mBAAiB,sBAAjB,mBAAoC;AAAA,QACtC;AAAA,MACF,SAAS,OAAP;AACA,gBAAQ,MAAM,6BAA6B,KAAK;AAChD;AAAA,MACF;AAAA,IACF;AAAA,EACF,OAGK;AACH,8BAA0B,YAAY,OAAO,MAAM,MAAM;AAAA,EAC3D;AACF;AAWO,SAAS,4BACd,QACA,SACA,QAAiB,OACD;AAChB,QAAM,kBAAkB,QAAQ;AAAA,IAC9B,CAAC,KAAK,OAAO;AACX,UAAI,GAAG,IAAI,IAAI;AACf,aAAO;AAAA,IACT;AAAA,IACA,CAAC;AAAA,EACH;AAEA,QAAM,oBAAgB,oCAAoB,MAAM;AAChD,QAAM,SAAS,cAAc,UAAU;AAEvC,iBAAe,QAAQ,YAAmD;AACxE,QAAI,YAAY;AACd,UAAI;AACF,mBAAW,MAAM;AAAA,MACnB,SAAS,GAAP;AAAA,MAAW;AAAA,IACf;AACA,QAAI,QAAQ;AACV,UAAI;AACF,cAAM,OAAO,OAAO;AAAA,MACtB,SAAS,GAAP;AAAA,MAAW;AAAA,IACf;AAAA,EACF;AAOA,MAAI,0BAA0B;AAE9B,MAAI,mBAAmB;AACvB,MAAI,wBAAwB;AAE5B,MAAI,iBAAgC;AAEpC,QAAM,oBAAoB,OACxB,eACkB;AAClB,UAAM,SAAS,gBAAgB,gBAAgB;AAC/C,UAAM,oBAAoB,YAAY,QAAQ,qBAAqB;AAEnE,8BAA0B;AAC1B,uBAAmB;AACnB,4BAAwB;AAAA,EAC1B;AAEA,SAAO,IAAI,eAAe;AAAA,IACxB,MAAM,KAAK,YAAY;AA/I3B;AAgJM,aAAO,MAAM;AACX,YAAI;AACF,gBAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAE1C,cAAI,MAAM;AACR,gBAAI,OAAO;AACT,sBAAQ,IAAI,kBAAkB;AAAA,YAChC;AACA,gBAAI,yBAAyB;AAE3B,oBAAM,kBAAkB,UAAU;AAAA,YACpC;AACA,mCAAuB,UAAU;AACjC,kBAAM,QAAQ,UAAU;AACxB;AAAA,UACF;AAEA,cAAI,OAAO;AACT,oBAAQ,IAAI,WAAW,KAAK,UAAU,KAAK,IAAI,MAAM;AAAA,UACvD;AAIA,cAAI;AACJ,gBAAM,iBAAgB,WAAM,QAAQ,CAAC,EAAE,MAAM,eAAvB,mBAAoC;AAC1D,cAAI,eAAe;AACjB,mBAAO,EAAE,MAAM,YAAY,UAAU,cAAc;AAAA,UACrD,OAAO;AACL,mBAAO,EAAE,MAAM,UAAU;AAAA,UAC3B;AAEA,gBAAM,iBAAiB,KAAK,SAAS,aAAa,KAAK,SAAS,QAAQ;AAIxE,cACE,4BACC,KAAK,QAAQ,cAAc,kBAAkB,iBAC9C;AACA,kBAAM,kBAAkB,UAAU;AAAA,UACpC;AACA,2BAAiB;AAGjB,cAAI,KAAK,SAAS,WAAW;AAC3B,gBAAI,MAAM,QAAQ,CAAC,EAAE,MAAM,SAAS;AAClC,uCAAyB,YAAY,KAAK;AAAA,YAC5C;AACA;AAAA,UACF,WAGS,KAAK,SAAS,YAAY;AAEjC,kBAAM,oBAAoB,KAAK,SAAS,SAAS;AACjD,gBAAI,mBAAmB;AACrB,iCAAmB;AAAA,YACrB;AAEA,kBAAM,iBAAiB,KAAK,SAAS,SAAS;AAC9C,gBAAI,KAAK,SAAS,SAAS,WAAW;AACpC,uCAAyB;AAAA,YAC3B;AACA,gBAAI,CAAC,yBAAyB;AAE5B,kBAAI,oBAAoB,iBAAiB;AACvC,0CAA0B;AAAA,cAC5B;AAAA,YACF;AACA,iBAAK,SAAS,SAAS,QAAQ,0BAA0B,WAAW;AACpE,qCAAyB,YAAY,KAAK;AAC1C;AAAA,UACF;AAAA,QACF,SAAS,OAAP;AACA,qBAAW,MAAM,KAAK;AACtB;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,IACA,SAAS;AACP,aAAO,OAAO;AAAA,IAChB;AAAA,EACF,CAAC;AACH;AAKO,IAAM,4BAAN,cAAwC,eAAoB;AAAA,EACjE,YAAY,UAAkB,IAAI,WAAiB;AACjD,UAAM;AAAA,MACJ,MAAM,YAAY;AAChB,cAAM,QAA6B;AAAA,UACjC,SAAS;AAAA,YACP;AAAA,cACE,OAAO;AAAA,gBACL,MAAM;AAAA,gBACN;AAAA,gBACA,GAAI,YAAY,EAAE,YAAY,UAAU,IAAI,CAAC;AAAA,cAC/C;AAAA,YACF;AAAA,UACF;AAAA,QACF;AACA,iCAAyB,YAAY,KAAK;AAC1C,+BAAuB,UAAU;AAEjC,mBAAW,MAAM;AAAA,MACnB;AAAA,MACA,SAAS;AAAA,MAAC;AAAA,IACZ,CAAC;AAAA,EACH;AACF;","names":["import_shared"]}