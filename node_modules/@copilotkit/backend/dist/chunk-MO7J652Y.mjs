import {
  limitOpenAIMessagesToTokenCount,
  maxTokensForOpenAIModel
} from "./chunk-P7GKPATA.mjs";

// src/lib/openai-adapter.ts
import OpenAI from "openai";
var DEFAULT_MODEL = "gpt-4-1106-preview";
var OpenAIAdapter = class {
  constructor(params) {
    this.model = DEFAULT_MODEL;
    this._openai = (params == null ? void 0 : params.openai) || new OpenAI({});
    if (params == null ? void 0 : params.model) {
      this.model = params.model;
    }
  }
  get openai() {
    return this._openai;
  }
  async getResponse(forwardedProps) {
    forwardedProps = { ...forwardedProps };
    if (forwardedProps.tools && forwardedProps.tools.length === 0) {
      delete forwardedProps.tools;
    }
    const messages = limitOpenAIMessagesToTokenCount(
      forwardedProps.messages || [],
      forwardedProps.tools || [],
      maxTokensForOpenAIModel(forwardedProps.model || this.model)
    );
    return new Promise((resolve, reject) => {
      messages.forEach((message) => {
        var _a;
        if ((_a = message.function_call) == null ? void 0 : _a.scope) {
          delete message.function_call.scope;
        }
      });
      const stream = this.openai.beta.chat.completions.stream({
        model: this.model,
        ...forwardedProps,
        stream: true,
        messages
      });
      stream.on("error", (error) => {
        reject(error);
      });
      stream.on("connect", () => {
        resolve({ stream: stream.toReadableStream() });
      });
    });
  }
};

export {
  OpenAIAdapter
};
//# sourceMappingURL=chunk-MO7J652Y.mjs.map